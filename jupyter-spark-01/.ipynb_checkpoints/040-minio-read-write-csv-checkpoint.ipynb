{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91284b97-16a1-48a9-8444-32f1d51f9588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.4.1\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.17, OpenJDK 64-Bit Server VM, 17.0.8\n",
      "Branch HEAD\n",
      "Compiled by user centos on 2023-06-19T23:01:01Z\n",
      "Revision 6b1ff22dde1ead51cbf370be6e48a802daae58b6\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!spark-shell --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002f41a8-c8b6-4b71-8c4a-7f705d65aebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minio in /opt/conda/lib/python3.11/site-packages (7.1.16)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from minio) (2023.7.22)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.11/site-packages (from minio) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install  minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9255c3fd-b0e4-4b2a-920d-0ad8a98ae6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#generate 4-columns data\n",
    "data = np.random.rand(1000,5)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"random_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94087c5d-b552-400b-bc8a-21b8d734d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME=\"jupyter-spark-01\"\n",
    "minio_url = \"minio-service.kubeflow.svc.cluster.local:9000\"\n",
    "minio_key = \"minio\"\n",
    "minio_secret = \"minio123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa36d41-a6b7-474b-b4ba-d0a6e23fc305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to minio minio-service.kubeflow.svc.cluster.local:9000\n",
      "try to find bucket jupyter-spark-01\n",
      "found True\n",
      "Bucket 'jupyter-spark-01' already exists\n",
      "upload file to minio...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<minio.helpers.ObjectWriteResult at 0x7fb87f785950>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import os\n",
    "\n",
    "upload_file_name=\"random_data.csv\"\n",
    "upload_file_path=\"./{}\".format(upload_file_name)\n",
    "config = {\n",
    "    \"endpoint\": minio_url,\n",
    "    \"access_key\": \"minio\",\n",
    "    \"secret_key\": \"minio123\",\n",
    "    \"secure\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create a client with the MinIO server playground, its access key\n",
    "# and secret key.\n",
    "print (\"connecting to minio {}\".format(minio_url))\n",
    "minio_client = Minio(**config)\n",
    "\n",
    "print(\"try to find bucket {}\".format(BUCKET_NAME))\n",
    "found = minio_client.bucket_exists(BUCKET_NAME)\n",
    "print(\"found\", found)\n",
    "if not found:\n",
    "    minio_client.make_bucket(BUCKET_NAME)\n",
    "else:\n",
    "    print(\"Bucket '{}' already exists\".format(BUCKET_NAME))\n",
    "\n",
    "print(\"upload file to minio...\")\n",
    "minio_client.fput_object(BUCKET_NAME, os.path.basename(upload_file_path), upload_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99caecf3-c211-4e06-b157-83c5674d0315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://jupyter-spark-01/random_data.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minio_file_path = 's3a://{}/{}'.format(BUCKET_NAME, upload_file_name)\n",
    "minio_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaafe06-0bfa-40e9-853f-9492bb48c58d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8062fbee-587c-49e4-8eb5-b6f5d5f4c7fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c3</th>\n",
       "      <th>_c4</th>\n",
       "      <th>_c5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.41820985915857456</td>\n",
       "      <td>0.09309416119920544</td>\n",
       "      <td>0.7301592997976444</td>\n",
       "      <td>0.44571530320065755</td>\n",
       "      <td>0.4856052119719031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.21461473789052588</td>\n",
       "      <td>0.42951363901677364</td>\n",
       "      <td>0.5156433054351429</td>\n",
       "      <td>0.02312015441580073</td>\n",
       "      <td>0.20032365884756587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.14853921690617045</td>\n",
       "      <td>0.9337026982275769</td>\n",
       "      <td>0.3367949865091945</td>\n",
       "      <td>0.42424893392327323</td>\n",
       "      <td>0.8592244463676983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9688173276276156</td>\n",
       "      <td>0.41144736146168137</td>\n",
       "      <td>0.16384465589047048</td>\n",
       "      <td>0.3446978863183656</td>\n",
       "      <td>0.9508910146867072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _c0                  _c1                  _c2                  _c3  \\\n",
       "0  None                    0                    1                    2   \n",
       "1     0  0.41820985915857456  0.09309416119920544   0.7301592997976444   \n",
       "2     1  0.21461473789052588  0.42951363901677364   0.5156433054351429   \n",
       "3     2  0.14853921690617045   0.9337026982275769   0.3367949865091945   \n",
       "4     3   0.9688173276276156  0.41144736146168137  0.16384465589047048   \n",
       "\n",
       "                   _c4                  _c5  \n",
       "0                    3                    4  \n",
       "1  0.44571530320065755   0.4856052119719031  \n",
       "2  0.02312015441580073  0.20032365884756587  \n",
       "3  0.42424893392327323   0.8592244463676983  \n",
       "4   0.3446978863183656   0.9508910146867072  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%writefile spark_main.py\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# .config(\"spark.jars\", \"spark_jars/hadoop-aws-2.7.3.jar\") \\\n",
    "#.config('spark.jars.packages','org.apache.hadoop:hadoop-aws:2.7.3')\\\n",
    "#.config(\"spark.executor.extraClassPath\", f\"{cwd}/spark_jars/hadoop-aws-2.7.3.jar\")\\\n",
    "#.config(\"spark.jars\", f\"{cwd}/spark_jars/hadoop-aws-2.7.3.jar\")\\\n",
    "#.config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.3\")\\\n",
    "#.config('spark.jars.packages','org.apache.hadoop:hadoop-aws:3.3.6')\\\n",
    "\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.hadoop:hadoop-aws:3.3.6 pyspark-shell'\n",
    "#.config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\\\n",
    "#.config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\\\n",
    "\n",
    "\n",
    "minio_url = \"minio-service.kubeflow.svc.cluster.local:9000\"\n",
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".appName(\"ReadTextFilesFromS3\")\\\n",
    ".master(\"local[*]\")\\\n",
    ".config('spark.jars.packages','org.apache.hadoop:hadoop-aws:3.3.4')\\\n",
    ".config(\"spark.hadoop.fs.s3a.endpoint\", \"http://\"+minio_url)\\\n",
    ".config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    ".config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\\\n",
    ".config(\"spark.hadoop.fs.s3a.access.key\", \"minio\")\\\n",
    ".config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\")\\\n",
    ".getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "minio_file_path = \"s3a://jupyter-spark-01/random_data.csv\"\n",
    "df = spark.read.csv(minio_file_path,header=False)\n",
    "df.toPandas().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22a5ebb-5578-4bdf-b9a9-dae2c6457bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_new_csv_path=\"{}.new.csv\".format(\"random_data.csv\")\n",
    "df.write.format('csv').options(delimiter=',').mode('overwrite').save(minio_new_csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
